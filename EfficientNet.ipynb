{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOP+mnc6lBSASTnl1mwnX/Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"TPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eS8ZCmFwNIug","executionInfo":{"status":"ok","timestamp":1677782938753,"user_tz":-480,"elapsed":13360,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"2a391c76-9c0c-4b81-f66b-d77e2d2ee6ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU Device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"WbUpJA0ONNMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install efficientnet\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","import efficientnet.keras as efn\n","from tensorflow.keras.datasets import cifar100\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, Dropout,BatchNormalization,GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import os\n","from keras.callbacks import ModelCheckpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfI5Qr1JNctY","executionInfo":{"status":"ok","timestamp":1677782949485,"user_tz":-480,"elapsed":10747,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"c124b64b-8cfe-4123-aa2e-6a91498bbb05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: efficientnet in /usr/local/lib/python3.8/dist-packages (1.1.1)\n","Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from efficientnet) (1.0.8)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from efficientnet) (0.19.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (8.4.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.10.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2.9.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2023.2.27)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (23.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uah2CFQI-deJ","executionInfo":{"status":"ok","timestamp":1677782968854,"user_tz":-480,"elapsed":14668,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"83130ce2-dd22-41f0-c73b-252f46015feb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169001437/169001437 [==============================] - 11s 0us/step\n"]}],"source":["# Define image size and batch size\n","TARGET_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","\n","# Define data generators for train and validation data\n","(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n","\n","# Convert labels to one-hot encoding\n","train_labels = to_categorical(train_labels, num_classes=100)\n","test_labels = to_categorical(test_labels, num_classes=100)"]},{"cell_type":"code","source":["# Resize train images in batches\n","num_batches = int(np.ceil(len(train_images) / BATCH_SIZE))\n","resized_images = []\n","for i in range(num_batches):\n","    batch_start = i * BATCH_SIZE\n","    batch_end = (i + 1) * BATCH_SIZE\n","    batch_images = train_images[batch_start:batch_end]\n","    batch_resized = []\n","    for img in batch_images:\n","        img_resized = tf.image.resize(img, TARGET_SIZE)\n","        batch_resized.append(img_resized)\n","    resized_images.append(np.array(batch_resized))\n","\n","train_images_resized = np.concatenate(resized_images, axis=0)"],"metadata":{"id":"XxCR1hvBcgew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resize test images in batches\n","num_batches = int(np.ceil(len(test_images) / BATCH_SIZE))\n","resized_images = []\n","for i in range(num_batches):\n","    batch_start = i * BATCH_SIZE\n","    batch_end = (i + 1) * BATCH_SIZE\n","    batch_images = test_images[batch_start:batch_end]\n","    batch_resized = []\n","    for img in batch_images:\n","        img_resized = tf.image.resize(img, TARGET_SIZE)\n","        batch_resized.append(img_resized)\n","    resized_images.append(np.array(batch_resized))\n","\n","test_images_resized = np.concatenate(resized_images, axis=0)"],"metadata":{"id":"xakW_K5nbKwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the train and test resized images\n","#np.save('/content/drive/MyDrive/Colab Notebooks/train_images_resized.npy', train_images_resized)\n","np.save('/content/drive/MyDrive/Colab Notebooks/test_images_resized.npy', test_images_resized)"],"metadata":{"id":"xQMDRkIJbU1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the train and test resized images \n","#train_images_resized = np.load('/content/drive/MyDrive/Colab Notebooks/train_images_resized.npy')\n","test_images_resized = np.load('/content/drive/MyDrive/Colab Notebooks/test_images_resized.npy')"],"metadata":{"id":"ByavcPt3cVdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define data generators for train and validation data\n","train_datagen = ImageDataGenerator(rotation_range=0.1,\n","                                   shear_range=0.2, \n","                                   zoom_range=0.2, \n","                                   horizontal_flip=True, \n","                                   vertical_flip=False,\n","                                   validation_split=0.2)\n","\n","train_generator = train_datagen.flow(train_images_resized, train_labels, \n","                                     batch_size=BATCH_SIZE, \n","                                     subset='training')\n","\n","val_generator = train_datagen.flow(train_images_resized, train_labels, \n","                                   batch_size=BATCH_SIZE, \n","                                   subset='validation')"],"metadata":{"id":"yqbuXakScdgB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialise the base model\n","efnb0 = efn.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*TARGET_SIZE, 3), classes=100)\n","model = Sequential()\n","model.add(efnb0)\n","\n","# Add new layers on top of the pre-trained model\n","model.add(GlobalAveragePooling2D())\n","model.add(Dropout(0.5))\n","model.add(Dense(100, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxzwnMv7ONLk","executionInfo":{"status":"ok","timestamp":1677746523268,"user_tz":-480,"elapsed":3909,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"bf1c8eb8-428c-40a4-a820-646736223db0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnet-b0 (Functional  (None, 7, 7, 1280)       4049564   \n"," )                                                               \n","                                                                 \n"," global_average_pooling2d_1   (None, 1280)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1280)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               128100    \n","                                                                 \n","=================================================================\n","Total params: 4,177,664\n","Trainable params: 4,135,648\n","Non-trainable params: 42,016\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Set up callbacks\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","\n","early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n","\n","learning_rate_reduction = ReduceLROnPlateau(\n","    monitor='val_accuracy', \n","    patience=3, \n","    verbose=1, \n","    factor=0.6, \n","    min_lr=1e-6)\n","\n","checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\", monitor='val_accuracy', verbose=1,\n","    save_best_only=True, mode='auto')"],"metadata":{"id":"mOFwsPS7a3qW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(train_generator, \n","                    steps_per_epoch=len(train_generator),\n","                    epochs=10, \n","                    validation_data=val_generator, \n","                    validation_steps=len(val_generator),\n","                    callbacks=[early_stop, learning_rate_reduction, checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-UL0W_Iai_L","executionInfo":{"status":"ok","timestamp":1677751321982,"user_tz":-480,"elapsed":4780607,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"870c9ba4-92d7-497a-e4d2-1604e70a0c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1250/1250 [==============================] - ETA: 0s - loss: 2.4202 - accuracy: 0.4188\n","Epoch 1: val_accuracy improved from -inf to 0.71740, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 524s 378ms/step - loss: 2.4202 - accuracy: 0.4188 - val_loss: 0.9740 - val_accuracy: 0.7174 - lr: 1.0000e-04\n","Epoch 2/10\n","1250/1250 [==============================] - ETA: 0s - loss: 1.0699 - accuracy: 0.6935\n","Epoch 2: val_accuracy improved from 0.71740 to 0.78670, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 473s 378ms/step - loss: 1.0699 - accuracy: 0.6935 - val_loss: 0.7011 - val_accuracy: 0.7867 - lr: 1.0000e-04\n","Epoch 3/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.7671\n","Epoch 3: val_accuracy improved from 0.78670 to 0.80920, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 472s 377ms/step - loss: 0.7906 - accuracy: 0.7671 - val_loss: 0.6398 - val_accuracy: 0.8092 - lr: 1.0000e-04\n","Epoch 4/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.8065\n","Epoch 4: val_accuracy improved from 0.80920 to 0.82580, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 474s 379ms/step - loss: 0.6447 - accuracy: 0.8065 - val_loss: 0.5861 - val_accuracy: 0.8258 - lr: 1.0000e-04\n","Epoch 5/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.8361\n","Epoch 5: val_accuracy improved from 0.82580 to 0.83300, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 473s 378ms/step - loss: 0.5357 - accuracy: 0.8361 - val_loss: 0.5639 - val_accuracy: 0.8330 - lr: 1.0000e-04\n","Epoch 6/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8570\n","Epoch 6: val_accuracy improved from 0.83300 to 0.83790, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 474s 379ms/step - loss: 0.4629 - accuracy: 0.8570 - val_loss: 0.5466 - val_accuracy: 0.8379 - lr: 1.0000e-04\n","Epoch 7/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8758\n","Epoch 7: val_accuracy did not improve from 0.83790\n","1250/1250 [==============================] - 472s 377ms/step - loss: 0.4002 - accuracy: 0.8758 - val_loss: 0.5796 - val_accuracy: 0.8343 - lr: 1.0000e-04\n","Epoch 8/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.8916\n","Epoch 8: val_accuracy did not improve from 0.83790\n","1250/1250 [==============================] - 474s 380ms/step - loss: 0.3419 - accuracy: 0.8916 - val_loss: 0.5733 - val_accuracy: 0.8359 - lr: 1.0000e-04\n","Epoch 9/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.9038\n","Epoch 9: val_accuracy improved from 0.83790 to 0.84180, saving model to /content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\n","1250/1250 [==============================] - 474s 379ms/step - loss: 0.3024 - accuracy: 0.9038 - val_loss: 0.5732 - val_accuracy: 0.8418 - lr: 1.0000e-04\n","Epoch 10/10\n","1250/1250 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9148\n","Epoch 10: val_accuracy did not improve from 0.84180\n","1250/1250 [==============================] - 469s 375ms/step - loss: 0.2671 - accuracy: 0.9148 - val_loss: 0.5780 - val_accuracy: 0.8410 - lr: 1.0000e-04\n"]}]},{"cell_type":"code","source":["plt.subplots(figsize=(6,4))\n","plt.plot(history.epoch,history.history[\"loss\"],color=\"green\",label=\"Train Loss\")\n","plt.plot(history.epoch,history.history[\"val_loss\"],color=\"blue\",label=\"Validation Loss\")\n","plt.xlabel(\"Epoch Number\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.title(\"Loss Graph\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"nVFCXUatexs6","executionInfo":{"status":"ok","timestamp":1677751321983,"user_tz":-480,"elapsed":42,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"633a2fa8-5e4b-414c-d52b-737afca02ca9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.subplots(figsize=(6,4))\n","plt.plot(history.epoch,history.history[\"accuracy\"],color=\"green\",label=\"Train Accuracy\")\n","plt.plot(history.epoch,history.history[\"val_accuracy\"],color=\"blue\",label=\"Validation Accuracy\")\n","plt.xlabel(\"Epoch Number\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.title(\"Accuracy Graph\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"v_frtOh1fPSG","executionInfo":{"status":"ok","timestamp":1677751321983,"user_tz":-480,"elapsed":39,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"3fcca785-dc27-4461-b827-e1624f2f63a4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["model.save(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\")"],"metadata":{"id":"sYhIEMAexnlg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\")"],"metadata":{"id":"drii_qYnhQ2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate model on test data\n","test_loss, test_acc = model.evaluate(test_images_resized, test_labels, verbose=0)\n","print(\"Test accuracy without attack: {:.4f}\".format(test_acc))"],"metadata":{"id":"zJmEU8NYsCqW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677781340668,"user_tz":-480,"elapsed":91546,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"e9ad8d43-20e9-4b87-88b1-4e22d6806a79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy without attack: 0.8485\n"]}]},{"cell_type":"code","source":["# Make predictions on the test data\n","y_pred = model.predict(test_images_resized)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(test_labels, axis=1)\n","\n","# Find the indices of the correctly predicted samples\n","correct_indices = np.nonzero(y_pred_classes == y_true_classes)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csvLFe_CxBae","executionInfo":{"status":"ok","timestamp":1677785064893,"user_tz":-480,"elapsed":203951,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"37fe5437-ae08-483e-f90b-491a47f9a6ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 203s 643ms/step\n"]}]},{"cell_type":"code","source":["# Select a random sample of 2500 correctly predicted samples\n","num_samples = 2500\n","selected_indices = np.random.choice(correct_indices, num_samples, replace=False)\n","selected_images = test_images_resized[selected_indices]\n","selected_labels = test_labels[selected_indices]\n","\n","print('Selected images shape:', selected_images.shape)\n","print('Selected labels shape:', selected_labels.shape)\n","\n","# Save the selected images and labels\n","np.save('/content/drive/MyDrive/Colab Notebooks/selected_images.npy', selected_images)\n","np.save('/content/drive/MyDrive/Colab Notebooks/selected_labels.npy', selected_labels)"],"metadata":{"id":"UO6AJBzCsD8B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677785074389,"user_tz":-480,"elapsed":7423,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"b968aa43-450c-4d3c-dfa0-fa5b7ade8ff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected images shape: (2500, 224, 224, 3)\n","Selected labels shape: (2500, 100)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","selected_images = np.load('/content/drive/MyDrive/Colab Notebooks/selected_images.npy')\n","selected_labels = np.load('/content/drive/MyDrive/Colab Notebooks/selected_labels.npy')\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\")"],"metadata":{"id":"EemM7hMokMme"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Generating Adversarial Examples using Fast Gradient Sign Method (FGSM)**"],"metadata":{"id":"iWThNjLakcUA"}},{"cell_type":"code","source":["# Define the FGSM attack function\n","def fgsm_attack(model, images, labels, eps, batch_size=50):\n","  \n","    adv_images = []\n","    num_batches = int(np.ceil(len(images) / batch_size))\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = min(start_idx + batch_size, len(images))\n","        batch_images = images[start_idx:end_idx]\n","        batch_labels = labels[start_idx:end_idx]\n","\n","        # Compute the gradient of the loss with respect to the input\n","        x_tensor = tf.convert_to_tensor(batch_images, dtype=tf.float32)\n","        # Record the gradient tape\n","        with tf.GradientTape() as tape:\n","            tape.watch(x_tensor)\n","            y_pred = model(x_tensor)\n","            loss_value = tf.keras.losses.categorical_crossentropy(batch_labels, y_pred)\n","        gradient = tape.gradient(loss_value, x_tensor)\n","\n","        # Generate the adversarial examples with FGSM\n","        adv_images_batch = batch_images + eps * tf.sign(gradient)\n","        adv_images_batch = tf.clip_by_value(adv_images_batch, 0, 1)\n","    \n","        # Compute the adversarial examples for the batch\n","        adv_images.extend(adv_images_batch.numpy())\n","    \n","    return adv_images"],"metadata":{"id":"lwCI9OWekZwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform the FGSM attack on the sample of test images\n","eps = 0.1\n","adv_images = fgsm_attack(model, selected_images, selected_labels, eps)\n","\n","# Save the adversarial images to a numpy file\n","np.save('/content/drive/MyDrive/Colab Notebooks/adv_images_fgsm.npy', adv_images)\n","# Evaluate the accuracy of the classification on the original and perturbed images\n","acc_orig = model.evaluate(selected_images, selected_labels, verbose=0)[1]\n","acc_adv = model.evaluate(np.array(adv_images), selected_labels, verbose=0)[1]\n","\n","print('Accuracy of benign images: {:4f}'.format(acc_orig))\n","print('Accuracy of adversarial examples: {:4f}'.format(acc_adv))"],"metadata":{"id":"qRe6BrMfkhAx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677785484580,"user_tz":-480,"elapsed":394769,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"85b3cc57-cfca-41b9-9ed5-d40f338c4ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of benign images: 1.000000\n","Accuracy of adversarial examples: 0.011200\n"]}]},{"cell_type":"markdown","source":["**Defence against FGSM Attack**"],"metadata":{"id":"XNiKgSOYleBM"}},{"cell_type":"code","source":["# Load the fgsm adversarial images from the numpy file \n","import numpy as np\n","import tensorflow as tf\n","\n","num_samples = 2500\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\")\n","adv_images = np.load('/content/drive/MyDrive/Colab Notebooks/adv_images_fgsm.npy')"],"metadata":{"id":"Q45DauYvlkjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from PIL import Image\n","from io import BytesIO\n","import datetime\n","\n","# Perform fliplr on the adversarial images\n","x_fliplr = np.fliplr(adv_images)\n","\n","for quality in [0, 25, 50, 75, 100]:\n","    print('--- For Quality Factor : {} ---'.format(quality))\n","    # Save the fliplr adversarial images and perform webp compression\n","    start_time = datetime.datetime.now()\n","\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(x_fliplr[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images/fliplr_adv_{}_{}.webp'.format(i, quality), 'webp', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average time taken to save 1 fliplr adversarial image with webp compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/2500))\n","\n","    start_time = datetime.datetime.now()\n","\n","    # Perform webp compression on the adversarial images without fliplr\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(adv_images[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.webp'.format(i, quality), 'webp', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average time taken to save 1 original adversarial image with webp compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/2500))\n","\n","    start_time = datetime.datetime.now()\n","    \n","    # Perform jpg compression on the adversarial images without fliplr\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(adv_images[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.jpg'.format(i, quality), 'jpeg', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average Time taken to save 1 original adversarial image with jpg compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/2500))\n","    \n","     # Load the fliplr adversarial images\n","    x_fliplr = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images/fliplr_adv_{}_{}.webp'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the fliplr adversarial examples\n","    y_pred = model.predict(x_fliplr)\n","    acc_fliplr = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with fliplr and webp compression:', acc_fliplr)\n","\n","    # Load the webp compressed adversarial images\n","    x_webp = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.webp'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the webp compressed adversarial examples\n","    y_pred = model.predict(x_webp)\n","    acc_webp = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with webp compression:', acc_webp)\n","\n","    # Load the jpg compressed adversarial images\n","    x_jpg = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.jpg'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the jpg compressed adversarial examples\n","    y_pred = model.predict(x_jpg)\n","    acc_jpg = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with jpeg compression:', acc_jpg)"],"metadata":{"id":"oFtWTFMRlfCX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677787023705,"user_tz":-480,"elapsed":1398859,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"26018796-d683-42dc-8af7-47076fcc52b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- For Quality Factor : 0 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0097 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0096 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0064 seconds\n","79/79 [==============================] - 52s 631ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 48s 611ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 58s 722ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 25 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0116 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0114 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0074 seconds\n","79/79 [==============================] - 52s 656ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 50s 632ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 49s 624ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 50 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0096 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0094 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0069 seconds\n","79/79 [==============================] - 53s 665ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 49s 622ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 72s 918ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 75 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0091 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0088 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0064 seconds\n","79/79 [==============================] - 49s 622ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 49s 619ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 48s 606ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 100 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0108 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0088 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0065 seconds\n","79/79 [==============================] - 49s 618ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 48s 612ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 49s 621ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n"]}]},{"cell_type":"markdown","source":["**Generating Adversarial Examples using Iterative Fast Gradient Sign Method (IFGSM)** "],"metadata":{"id":"9O1I--Zimifd"}},{"cell_type":"code","source":["def ifgsm_batch(model, images, labels, eps=0.01, alpha=0.005, num_iter=10, batch_size=50):\n","    \"\"\"\n","    Implements the iterative fast gradient sign method (IFGSM) attack on a given model.\n","    \n","    Args:\n","    - model: the target model to attack\n","    - images: a batch of input images to be attacked\n","    - labels: the true labels for the input images\n","    - eps: the maximum perturbation that can be added to each pixel (default: 0.01)\n","    - alpha: the step size for each iteration of the attack (default: 0.005)\n","    - num_iter: the number of iterations to run the attack (default: 10)\n","    - batch_size: the number of images to attack at once (default: 50)\n","    \n","    Returns:\n","    - adv_images: the adversarial images generated by the attack\n","    \"\"\"\n","    adv_images = []\n","    num_batches = int(np.ceil(len(images) / batch_size))\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = min(start_idx + batch_size, len(images))\n","        batch_images = images[start_idx:end_idx]\n","        batch_labels = labels[start_idx:end_idx]\n","\n","        # Create a tensor from the batch images\n","        x = tf.convert_to_tensor(batch_images, dtype=tf.float32)\n","\n","        # Iterate the FGSM attack\n","        for j in range(num_iter):\n","            with tf.GradientTape() as tape:\n","                tape.watch(x)\n","                pred = model(x)\n","                loss = tf.keras.losses.categorical_crossentropy(batch_labels, pred)\n","            grad = tape.gradient(loss, x)\n","            signed_grad = tf.sign(grad)\n","            x += alpha * signed_grad\n","            x = tf.clip_by_value(x, 0, 1)\n","\n","        # Compute the adversarial examples for the batch\n","        adv_images_batch = x.numpy()\n","        adv_images.extend(adv_images_batch)\n","\n","    return np.array(adv_images)\n"],"metadata":{"id":"Zzryf-gmmYXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate adversarial examples using IFGSM\n","adv_images = ifgsm_batch(model, selected_images, selected_labels, eps=0.01, alpha=0.005, num_iter=10, batch_size=50)\n","num_samples = 2500\n","\n","# Save the adversarial images to a numpy file\n","np.save('/content/drive/MyDrive/Colab Notebooks/adv_images_ifgsm.npy', adv_images)\n"],"metadata":{"id":"1eCXman8EYy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the accuracy of the classification on the original and perturbed images\n","acc_orig = model.evaluate(selected_images, selected_labels, verbose=0)[1]\n","acc_adv = model.evaluate(np.array(adv_images), selected_labels, verbose=0)[1]\n","\n","print('Accuracy of benign images: {:4f}'.format(acc_orig))\n","print('Accuracy of adversarial examples: {:4f}'.format(acc_adv))\n"],"metadata":{"id":"Unw4h93Rmbet","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677791933995,"user_tz":-480,"elapsed":168788,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"368bbbc1-717f-44aa-abf3-4490e125ac0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of benign images: 1.000000\n","Accuracy of adversarial examples: 0.000000\n"]}]},{"cell_type":"markdown","source":["**Defence against Iterative FGSM Attack**"],"metadata":{"id":"ZkoP-hBGmt2p"}},{"cell_type":"code","source":["# Load the ifgsm adversarial images from the numpy file \n","import numpy as np\n","import tensorflow as tf\n","\n","num_samples = 2500\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\")\n","adv_images = np.load('/content/drive/MyDrive/Colab Notebooks/adv_images_ifgsm.npy')\n","selected_labels = np.load('/content/drive/MyDrive/Colab Notebooks/selected_labels.npy')"],"metadata":{"id":"nR8zlVx5ma3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from PIL import Image\n","from io import BytesIO\n","import datetime\n","\n","# Perform fliplr on the adversarial images\n","x_fliplr = np.fliplr(adv_images)\n","\n","for quality in [0, 25, 50, 75, 100]:\n","    print('--- For Quality Factor : {} ---'.format(quality))\n","    # Save the fliplr adversarial images and perform webp compression\n","    start_time = datetime.datetime.now()\n","\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(x_fliplr[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images/fliplr_adv_{}_{}.webp'.format(i, quality), 'webp', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average time taken to save 1 fliplr adversarial image with webp compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/10000))\n","\n","    start_time = datetime.datetime.now()\n","\n","    # Perform webp compression on the adversarial images without fliplr\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(adv_images[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.webp'.format(i, quality), 'webp', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average time taken to save 1 original adversarial image with webp compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/10000))\n","\n","    start_time = datetime.datetime.now()\n","    \n","    # Perform jpg compression on the adversarial images without fliplr\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(adv_images[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.jpg'.format(i, quality), 'jpeg', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average Time taken to save 1 original adversarial image with jpg compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/10000))\n","    \n","     # Load the fliplr adversarial images\n","    x_fliplr = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images/fliplr_adv_{}_{}.webp'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the fliplr adversarial examples\n","    y_pred = model.predict(x_fliplr)\n","    acc_fliplr = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with fliplr and webp compression:', acc_fliplr)\n","\n","    # Load the webp compressed adversarial images\n","    x_webp = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.webp'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the webp compressed adversarial examples\n","    y_pred = model.predict(x_webp)\n","    acc_webp = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with webp compression:', acc_webp)\n","\n","    # Load the jpg compressed adversarial images\n","    x_jpg = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images/adv_{}_{}.jpg'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the jpg compressed adversarial examples\n","    y_pred = model.predict(x_jpg)\n","    acc_jpg = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with jpeg compression:', acc_jpg)"],"metadata":{"id":"p7fBOjErmUD9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677791764514,"user_tz":-480,"elapsed":2024023,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"8b67f68d-1863-4654-80ea-5bf3fc9b8299"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- For Quality Factor : 0 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0027 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0032 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0029 seconds\n","79/79 [==============================] - 78s 966ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 51s 644ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 50s 634ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 25 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0047 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0050 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0047 seconds\n","79/79 [==============================] - 49s 614ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 49s 626ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 50s 629ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 50 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0064 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0079 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0072 seconds\n","79/79 [==============================] - 50s 636ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 49s 620ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 50s 638ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 75 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0078 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0089 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0087 seconds\n","79/79 [==============================] - 76s 961ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 50s 632ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 50s 626ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 100 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0092 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0115 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0105 seconds\n","79/79 [==============================] - 51s 645ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 69s 873ms/step\n","Accuracy on adversarial examples with webp compression: 0.0\n","79/79 [==============================] - 50s 637ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0\n"]}]},{"cell_type":"markdown","source":["**Generating Adversarial Examples using Projected Gradient Descent (PGD)** "],"metadata":{"id":"tjGJc9Urna1D"}},{"cell_type":"code","source":["def pgd_batch(model, images, labels, eps=0.01, alpha=0.005, num_iter=10, \n","              batch_size=50):\n","    \"\"\"\n","    Implements the projected gradient descent (PGD) attack on a given model with \n","    random initialization of the starting point within a boundary.\n","    \n","    Args:\n","    - model: the target model to attack\n","    - images: a batch of input images to be attacked\n","    - labels: the true labels for the input images\n","    - eps: the maximum perturbation that can be added to each pixel \n","    (default: 0.01)\n","    - alpha: the step size for each iteration of the attack (default: 0.005)\n","    - num_iter: the number of iterations to run the attack (default: 10)\n","    - batch_size: the number of images to attack at once (default: 50)\n","    \n","    Returns:\n","    - adv_images: the adversarial images generated by the attack\n","    \"\"\"\n","    adv_images = []\n","    num_batches = int(np.ceil(len(images) / batch_size))\n","    for i in range(num_batches):\n","        start_idx = i * batch_size\n","        end_idx = min(start_idx + batch_size, len(images))\n","        batch_images = images[start_idx:end_idx]\n","        batch_labels = labels[start_idx:end_idx]\n","\n","        # Randomly perturb the batch images within the range [-eps, eps]\n","        perturbations = tf.random.uniform(shape=batch_images.shape, minval=-eps, \n","                                          maxval=eps)\n","        batch_images = tf.clip_by_value(batch_images + perturbations, 0, 1)\n","\n","        # Create a tensor from the batch images\n","        x = tf.convert_to_tensor(batch_images, dtype=tf.float32)\n","        \n","        # Initialize the perturbation to zero\n","        delta = tf.zeros_like(x)\n","\n","        # Iterate the PGD attack\n","        for j in range(num_iter):\n","            with tf.GradientTape() as tape:\n","                tape.watch(x)\n","                loss = tf.keras.losses.categorical_crossentropy(batch_labels, \n","                                                                model(x + delta))\n","            grad = tape.gradient(loss, x)\n","            signed_grad = tf.sign(grad)\n","            delta += alpha * signed_grad\n","            delta = tf.clip_by_value(delta, -eps, eps)\n","            x = tf.clip_by_value(x + delta, 0, 1)\n","\n","        # Compute the adversarial examples for the batch\n","        adv_images_batch = x.numpy()\n","        adv_images.extend(adv_images_batch)\n","\n","    return np.array(adv_images)\n"],"metadata":{"id":"OjbGA0XLnCY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate adversarial examples using PGD\n","adv_images = pgd_batch(model, selected_images, selected_labels)\n","num_samples = 2500\n","\n","# Save the adversarial images to a numpy file\n","np.save('/content/drive/MyDrive/Colab Notebooks/adv_images_pgd.npy', adv_images)\n","\n","# Evaluate the accuracy of the classification on the original and perturbed images\n","acc_orig = model.evaluate(selected_images, selected_labels, verbose=0)[1]\n","acc_adv = model.evaluate(np.array(adv_images), selected_labels, verbose=0)[1]\n","\n","print('Accuracy of benign images: {:4f}'.format(acc_orig))\n","print('Accuracy of adversarial examples: {:4f}'.format(acc_adv))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lvI51jcGXbx","executionInfo":{"status":"ok","timestamp":1677797054241,"user_tz":-480,"elapsed":2431008,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"4d49a6df-2b4c-4c2b-b820-73a6052f88cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of benign images: 1.000000\n","Accuracy of adversarial examples: 0.000000\n"]}]},{"cell_type":"markdown","source":["**Defence against PGD Attack**"],"metadata":{"id":"I8VkyNPYnEos"}},{"cell_type":"code","source":["# Load the pgd adversarial images from the numpy file \n","import numpy as np\n","import tensorflow as tf\n","\n","num_samples = 2500\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/EfficientNet_CIFAR100.hdf5\")\n","adv_images = np.load('/content/drive/MyDrive/Colab Notebooks/adv_images_pgd.npy')\n","selected_labels = np.load('/content/drive/MyDrive/Colab Notebooks/selected_labels.npy')"],"metadata":{"id":"2wp2ADkum0__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from PIL import Image\n","from io import BytesIO\n","import datetime\n","\n","# Perform fliplr on the adversarial images\n","x_fliplr = np.fliplr(adv_images)\n","\n","for quality in [0, 25, 50, 75, 100]:\n","    print('--- For Quality Factor : {} ---'.format(quality))\n","    # Save the fliplr adversarial images and perform webp compression\n","    start_time = datetime.datetime.now()\n","\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(x_fliplr[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images1/fliplr_adv_{}_{}.webp'.format(i, quality), 'webp', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average time taken to save 1 fliplr adversarial image with webp compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/2500))\n","\n","    start_time = datetime.datetime.now()\n","\n","    # Perform webp compression on the adversarial images without fliplr\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(adv_images[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images1/adv_{}_{}.webp'.format(i, quality), 'webp', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average time taken to save 1 original adversarial image with webp compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/2500))\n","\n","    start_time = datetime.datetime.now()\n","    \n","    # Perform jpg compression on the adversarial images without fliplr\n","    for i in range(num_samples):\n","        img = Image.fromarray(np.uint8(adv_images[i] * 255))\n","        img.save('/content/drive/MyDrive/Colab Notebooks/Images1/adv_{}_{}.jpg'.format(i, quality), 'jpeg', quality=quality)\n","    \n","    end_time = datetime.datetime.now()\n","    print('Average Time taken to save 1 original adversarial image with jpg compression: {:.4f} seconds'.format((end_time - start_time).total_seconds()/2500))\n","    \n","     # Load the fliplr adversarial images\n","    x_fliplr = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images1/fliplr_adv_{}_{}.webp'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the fliplr adversarial examples\n","    y_pred = model.predict(x_fliplr)\n","    acc_fliplr = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with fliplr and webp compression:', acc_fliplr)\n","\n","    # Load the webp compressed adversarial images\n","    x_webp = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images1/adv_{}_{}.webp'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the webp compressed adversarial examples\n","    y_pred = model.predict(x_webp)\n","    acc_webp = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with webp compression:', acc_webp)\n","\n","    # Load the jpg compressed adversarial images\n","    x_jpg = np.array([np.array(Image.open('/content/drive/MyDrive/Colab Notebooks/Images1/adv_{}_{}.jpg'.format(i, quality))) / 255. for i in range(num_samples)])\n","\n","    # Evaluate the accuracy of the classification on the jpg compressed adversarial examples\n","    y_pred = model.predict(x_jpg)\n","    acc_jpg = np.mean(np.equal(np.argmax(y_pred, axis=1), np.argmax(selected_labels, axis=1)))\n","    print('Accuracy on adversarial examples with jpeg compression:', acc_jpg)"],"metadata":{"id":"SWLjUyRpmUp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677798757297,"user_tz":-480,"elapsed":1694768,"user":{"displayName":"Stanley Ho (Beaniestanley)","userId":"05013297724408737212"}},"outputId":"20848f61-4bd4-48fe-e8ac-3cf1fe4e24ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- For Quality Factor : 0 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0123 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0137 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0128 seconds\n","79/79 [==============================] - 52s 634ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 50s 637ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 50s 627ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 25 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0185 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0222 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0184 seconds\n","79/79 [==============================] - 74s 947ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 51s 650ms/step\n","Accuracy on adversarial examples with webp compression: 0.0112\n","79/79 [==============================] - 53s 669ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 50 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0264 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0322 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0266 seconds\n","79/79 [==============================] - 58s 731ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 55s 698ms/step\n","Accuracy on adversarial examples with webp compression: 0.0\n","79/79 [==============================] - 49s 617ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0112\n","--- For Quality Factor : 75 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0123 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0141 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0077 seconds\n","79/79 [==============================] - 50s 635ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 51s 646ms/step\n","Accuracy on adversarial examples with webp compression: 0.0\n","79/79 [==============================] - 52s 659ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0\n","--- For Quality Factor : 100 ---\n","Average time taken to save 1 fliplr adversarial image with webp compression: 0.0104 seconds\n","Average time taken to save 1 original adversarial image with webp compression: 0.0188 seconds\n","Average Time taken to save 1 original adversarial image with jpg compression: 0.0101 seconds\n","79/79 [==============================] - 51s 640ms/step\n","Accuracy on adversarial examples with fliplr and webp compression: 0.0112\n","79/79 [==============================] - 51s 643ms/step\n","Accuracy on adversarial examples with webp compression: 0.0\n","79/79 [==============================] - 50s 636ms/step\n","Accuracy on adversarial examples with jpeg compression: 0.0\n"]}]}]}